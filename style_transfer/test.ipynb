{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unittest\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import transform\n",
    "import train\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 256, 256])\n",
      "torch.Size([10, 64, 128, 128])\n",
      "torch.Size([10, 128, 64, 64])\n",
      "torch.Size([10, 128, 64, 64])\n",
      "torch.Size([10, 128, 64, 64])\n",
      "torch.Size([10, 128, 64, 64])\n",
      "torch.Size([10, 64, 128, 128])\n",
      "torch.Size([10, 32, 256, 256])\n",
      "torch.Size([10, 3, 256, 256])\n",
      "torch.Size([10, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "importlib.reload(transform)\n",
    "model = transform.ImageTransformNet()\n",
    "x = torch.ones((10, 3, 256, 256)).to(device)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 65536])\n",
      "torch.Size([10, 65536, 3])\n",
      "torch.Size([10, 3, 3])\n",
      "torch.Size([10, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(train)\n",
    "x = torch.ones((10, 3, 256, 256))\n",
    "y = train.gram(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weilai/anaconda3/envs/mp5/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 256, 256]) torch.Size([10, 128, 128, 128]) torch.Size([10, 256, 64, 64]) torch.Size([10, 512, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vgg)\n",
    "model = vgg.vgg16()\n",
    "x = torch.ones((10, 3, 256, 256))\n",
    "y1, y2, y3, y4 = model(x)\n",
    "print(y1.shape, y2.shape, y3.shape, y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_scorenet(_):\n",
    "    setup_logging()\n",
    "    torch.set_num_threads(4)\n",
    "    torch.manual_seed(FLAGS.seed)\n",
    "\n",
    "    writer = SummaryWriter(FLAGS.output_dir, max_queue=1000, flush_secs=120)\n",
    "\n",
    "    if FLAGS.model_type == \"unet\":\n",
    "        net = UNet()\n",
    "    elif FLAGS.model_type == \"simple_fc\":\n",
    "        net = torch.nn.Sequential(\n",
    "          SimpleEncoder(input_size=1024, hidden_size=128, latent_size=16),\n",
    "          SimpleDecoder(latent_size=16, hidden_size=128, output_size=1024))\n",
    "    \n",
    "    scorenet = ScoreNet(net, FLAGS.sigma_begin, FLAGS.sigma_end,\n",
    "                        FLAGS.noise_level, FLAGS.sigma_type)\n",
    "    logging.info(f'Number of parameters in ScoreNet: {count_parameters(scorenet)}')\n",
    "    scorenet.train()\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Pad(2), transforms.ToTensor()])\n",
    "    dataset = datasets.MNIST(FLAGS.mnist_data_dir, train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=FLAGS.batch_size, shuffle=True)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    scorenet.to(device)\n",
    "    optimizer = optim.Adam(scorenet.parameters(), lr=FLAGS.lr)\n",
    "    iterations = 0\n",
    "\n",
    "    train_loss = []\n",
    "    for epoch in range(1, FLAGS.num_epochs + 1):\n",
    "        for batch_idx, (data, _) in enumerate(dataloader):\n",
    "            data = data.reshape(data.shape[0], -1)\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = scorenet.get_loss(data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += [loss.item()]\n",
    "            iterations += 1\n",
    "\n",
    "            if iterations % FLAGS.log_every == 0:\n",
    "                writer.add_scalar('loss', np.mean(train_loss), iterations)\n",
    "                logger('loss', np.mean(train_loss), iterations)\n",
    "                train_loss = []\n",
    "            \n",
    "            if iterations % FLAGS.sample_every == 0:\n",
    "                scorenet.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_gen = scorenet.sample(64, 1024, step_lr=FLAGS.step_lr)[-1, -1].view(-1, 1, 32, 32)\n",
    "                    \n",
    "                    samples_image = BytesIO()\n",
    "                    tvutils.save_image(X_gen, samples_image, 'png')\n",
    "                    samples_image = Image.open(samples_image)\n",
    "                    file_name = f'{FLAGS.output_dir}/samples_{iterations:08d}.png'\n",
    "                    samples_image.save(file_name)\n",
    "                    writer.add_image('samples', np.transpose(np.array(samples_image), [2,0,1]), iterations)\n",
    "\n",
    "                    X_gt = data.view(-1,1,32,32)[:64]\n",
    "                    gt_image = BytesIO()\n",
    "                    tvutils.save_image(X_gt, gt_image, 'png')\n",
    "                    gt_image = Image.open(gt_image)\n",
    "                    writer.add_image('gt', np.transpose(np.array(gt_image), [2,0,1]), iterations)\n",
    "                scorenet.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
